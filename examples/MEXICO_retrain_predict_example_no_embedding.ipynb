{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import hygia as hg\n",
    "import pickle\n",
    "import time"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classes instanciations\n",
    "\n",
    "NOTE: Please check if the model_path matches your path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mrunning feature engineering with configs below...\u001b[37m\n",
      "\u001b[1mlanguage -> \u001b[22mes\n",
      "\u001b[1mdimensions -> \u001b[22m25\n"
     ]
    }
   ],
   "source": [
    "pre_process_data = hg.PreProcessData(country=\"MEXICO\")\n",
    "augment_data = hg.AugmentData(country=\"MEXICO\")\n",
    "feature_engineering = hg.FeatureEngineering(country=\"MEXICO\")\n",
    "annotate_data = hg.AnnotateData()\n",
    "new_rf_model = hg.RandomForestModel()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data\n",
    "\n",
    "NOTE: Please check if the file_path matches your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '../data/tmp/AI_LATA_ADDRESS_MEX_modificado.csv'\n",
    "df = pd.read_csv(file_path, sep='Â¨', nrows=None, engine='python')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add new columns\n",
    "\n",
    "1. Concatenate address\n",
    "2. All features columns:\n",
    "    - Key Smash\n",
    "    - Regex\n",
    "    - Word Embedding\n",
    "\n",
    "NOTE: Please check if the columns names matches your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliases indified: \u001b[1mconcat_STREET_ADDRESS_1_STREET_ADDRESS_2 -> \u001b[22m['STREET_ADDRESS_1', 'STREET_ADDRESS_2']\n",
      "handle null values in the column \u001b[1mconcat_STREET_ADDRESS_1_STREET_ADDRESS_2\u001b[22m\n",
      "extract features from -> concat_STREET_ADDRESS_1_STREET_ADDRESS_2\n"
     ]
    }
   ],
   "source": [
    "concatened_column_name = 'concat_STREET_ADDRESS_1_STREET_ADDRESS_2'\n",
    "df = pre_process_data.pre_process_data(df, ['STREET_ADDRESS_1', 'STREET_ADDRESS_2'], concatened_column_name)\n",
    "df = feature_engineering.extract_features(df, concatened_column_name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check new columns names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['feature_ks_count_sequence_squared_vowels_concat_STREET_ADDRESS_1_STREET_ADDRESS_2',\n",
       " 'feature_ks_count_sequence_squared_consonants_concat_STREET_ADDRESS_1_STREET_ADDRESS_2',\n",
       " 'feature_ks_count_sequence_squared_special_characters_concat_STREET_ADDRESS_1_STREET_ADDRESS_2',\n",
       " 'feature_ks_ratio_of_numeric_digits_squared_concat_STREET_ADDRESS_1_STREET_ADDRESS_2',\n",
       " 'feature_ks_average_of_char_count_squared_concat_STREET_ADDRESS_1_STREET_ADDRESS_2',\n",
       " 'feature_we_0_concat_STREET_ADDRESS_1_STREET_ADDRESS_2',\n",
       " 'feature_we_1_concat_STREET_ADDRESS_1_STREET_ADDRESS_2',\n",
       " 'feature_we_2_concat_STREET_ADDRESS_1_STREET_ADDRESS_2',\n",
       " 'feature_we_3_concat_STREET_ADDRESS_1_STREET_ADDRESS_2',\n",
       " 'feature_we_4_concat_STREET_ADDRESS_1_STREET_ADDRESS_2',\n",
       " 'feature_we_5_concat_STREET_ADDRESS_1_STREET_ADDRESS_2',\n",
       " 'feature_we_6_concat_STREET_ADDRESS_1_STREET_ADDRESS_2',\n",
       " 'feature_we_7_concat_STREET_ADDRESS_1_STREET_ADDRESS_2',\n",
       " 'feature_we_8_concat_STREET_ADDRESS_1_STREET_ADDRESS_2',\n",
       " 'feature_we_9_concat_STREET_ADDRESS_1_STREET_ADDRESS_2',\n",
       " 'feature_we_10_concat_STREET_ADDRESS_1_STREET_ADDRESS_2',\n",
       " 'feature_we_11_concat_STREET_ADDRESS_1_STREET_ADDRESS_2',\n",
       " 'feature_we_12_concat_STREET_ADDRESS_1_STREET_ADDRESS_2',\n",
       " 'feature_we_13_concat_STREET_ADDRESS_1_STREET_ADDRESS_2',\n",
       " 'feature_we_14_concat_STREET_ADDRESS_1_STREET_ADDRESS_2',\n",
       " 'feature_we_15_concat_STREET_ADDRESS_1_STREET_ADDRESS_2',\n",
       " 'feature_we_16_concat_STREET_ADDRESS_1_STREET_ADDRESS_2',\n",
       " 'feature_we_17_concat_STREET_ADDRESS_1_STREET_ADDRESS_2',\n",
       " 'feature_we_18_concat_STREET_ADDRESS_1_STREET_ADDRESS_2',\n",
       " 'feature_we_19_concat_STREET_ADDRESS_1_STREET_ADDRESS_2',\n",
       " 'feature_we_20_concat_STREET_ADDRESS_1_STREET_ADDRESS_2',\n",
       " 'feature_we_21_concat_STREET_ADDRESS_1_STREET_ADDRESS_2',\n",
       " 'feature_we_22_concat_STREET_ADDRESS_1_STREET_ADDRESS_2',\n",
       " 'feature_we_23_concat_STREET_ADDRESS_1_STREET_ADDRESS_2',\n",
       " 'feature_we_24_concat_STREET_ADDRESS_1_STREET_ADDRESS_2',\n",
       " 'feature_re_contains_context_invalid_words_concat_STREET_ADDRESS_1_STREET_ADDRESS_2',\n",
       " 'feature_re_contains_exactly_the_word_dell_concat_STREET_ADDRESS_1_STREET_ADDRESS_2',\n",
       " 'feature_re_contains_exactly_the_word_test_concat_STREET_ADDRESS_1_STREET_ADDRESS_2',\n",
       " 'feature_re_only_numbers_concat_STREET_ADDRESS_1_STREET_ADDRESS_2',\n",
       " 'feature_re_only_special_characters_concat_STREET_ADDRESS_1_STREET_ADDRESS_2',\n",
       " 'feature_re_contains_email_concat_STREET_ADDRESS_1_STREET_ADDRESS_2',\n",
       " 'feature_re_contains_url_concat_STREET_ADDRESS_1_STREET_ADDRESS_2',\n",
       " 'feature_re_contains_date_concat_STREET_ADDRESS_1_STREET_ADDRESS_2',\n",
       " 'feature_re_contains_exactly_invalid_words_concat_STREET_ADDRESS_1_STREET_ADDRESS_2',\n",
       " 'feature_re_is_substring_of_column_name_concat_STREET_ADDRESS_1_STREET_ADDRESS_2',\n",
       " 'feature_re_only_one_char_concat_STREET_ADDRESS_1_STREET_ADDRESS_2',\n",
       " 'feature_re_only_white_spaces_concat_STREET_ADDRESS_1_STREET_ADDRESS_2',\n",
       " 'feature_re_empty_concat_STREET_ADDRESS_1_STREET_ADDRESS_2']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_features_columns = [col for col in df if col.startswith('feature_ks') or col.startswith('feature_we') or col.startswith('feature_re')]\n",
    "all_features_columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select Features\n",
    "- remove word embeddings\n",
    "- remove key smash feature: ratio_of_numeric_digits_squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['feature_ks_count_sequence_squared_vowels_concat_STREET_ADDRESS_1_STREET_ADDRESS_2',\n",
       " 'feature_ks_count_sequence_squared_consonants_concat_STREET_ADDRESS_1_STREET_ADDRESS_2',\n",
       " 'feature_ks_count_sequence_squared_special_characters_concat_STREET_ADDRESS_1_STREET_ADDRESS_2',\n",
       " 'feature_ks_average_of_char_count_squared_concat_STREET_ADDRESS_1_STREET_ADDRESS_2',\n",
       " 'feature_re_contains_context_invalid_words_concat_STREET_ADDRESS_1_STREET_ADDRESS_2',\n",
       " 'feature_re_contains_exactly_the_word_dell_concat_STREET_ADDRESS_1_STREET_ADDRESS_2',\n",
       " 'feature_re_contains_exactly_the_word_test_concat_STREET_ADDRESS_1_STREET_ADDRESS_2',\n",
       " 'feature_re_only_numbers_concat_STREET_ADDRESS_1_STREET_ADDRESS_2',\n",
       " 'feature_re_only_special_characters_concat_STREET_ADDRESS_1_STREET_ADDRESS_2',\n",
       " 'feature_re_contains_email_concat_STREET_ADDRESS_1_STREET_ADDRESS_2',\n",
       " 'feature_re_contains_url_concat_STREET_ADDRESS_1_STREET_ADDRESS_2',\n",
       " 'feature_re_contains_date_concat_STREET_ADDRESS_1_STREET_ADDRESS_2',\n",
       " 'feature_re_contains_exactly_invalid_words_concat_STREET_ADDRESS_1_STREET_ADDRESS_2',\n",
       " 'feature_re_is_substring_of_column_name_concat_STREET_ADDRESS_1_STREET_ADDRESS_2',\n",
       " 'feature_re_only_one_char_concat_STREET_ADDRESS_1_STREET_ADDRESS_2',\n",
       " 'feature_re_only_white_spaces_concat_STREET_ADDRESS_1_STREET_ADDRESS_2',\n",
       " 'feature_re_empty_concat_STREET_ADDRESS_1_STREET_ADDRESS_2']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_features = [col for col in all_features_columns \\\n",
    "                        if not col.startswith('feature_we') \\\n",
    "                        and 'ratio_of_numeric_digits_squared' not in col]\n",
    "selected_features"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Annotate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mrunning annotate data with configs below...\u001b[37m\n",
      "\u001b[1mthresholds -> \u001b[22m{'count_sequence_squared_vowels': 1.0, 'count_sequence_squared_consonants': 1.999, 'count_sequence_squared_special_characters': 2.2499, 'average_of_char_count_squared': 2.78}\n",
      "column -> concat_STREET_ADDRESS_1_STREET_ADDRESS_2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "valid                             1344254\n",
       "key_smash                             657\n",
       "contains_email                        569\n",
       "contains_exactly_the_word_test        177\n",
       "only_special_characters               144\n",
       "contains_context_invalid_words        128\n",
       "contains_exactly_the_word_dell        125\n",
       "only_numbers                          106\n",
       "only_one_char                          14\n",
       "contains_exactly_invalid_words         10\n",
       "is_substring_of_column_name             3\n",
       "contains_date                           1\n",
       "empty                                   1\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key_smash_thresholds = {\n",
    "    'count_sequence_squared_vowels': 1.00,\n",
    "    'count_sequence_squared_consonants': 1.999,\n",
    "    'count_sequence_squared_special_characters': 2.2499,\n",
    "    # 'ratio_of_numeric_digits_squared': 2.9,\n",
    "    'average_of_char_count_squared': 2.78,\n",
    "}\n",
    "\n",
    "df = annotate_data.annotate_data(df, concatened_column_name, key_smash_thresholds)\n",
    "df.drop_duplicates(subset=[concatened_column_name])['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "valid                             2511527\n",
       "contains_context_invalid_words       3079\n",
       "key_smash                            1494\n",
       "only_special_characters              1291\n",
       "contains_email                       1048\n",
       "contains_exactly_the_word_test        667\n",
       "contains_exactly_the_word_dell        553\n",
       "only_one_char                         287\n",
       "only_numbers                          239\n",
       "empty                                  71\n",
       "contains_exactly_invalid_words         26\n",
       "is_substring_of_column_name            12\n",
       "contains_date                           2\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['target'].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment: retrain model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mtranning model...\u001b[37m\n",
      "\u001b[32mdone\u001b[37m\n",
      "\u001b[33mget model score...\u001b[37m\n",
      "\u001b[1maccuracy -> \u001b[22m0.9987146529562982\n",
      "\u001b[1mprecision -> \u001b[22m0.9946524064171123\n",
      "\u001b[1mrecall -> \u001b[22m1.0\n",
      "\u001b[1mf1 -> \u001b[22m0.9973190348525469\n"
     ]
    }
   ],
   "source": [
    "scores = new_rf_model.train_and_get_scores(df, concatened_column_name, selected_features)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict using pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mrunning model...\u001b[37m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0    1345413\n",
       "1.0        776\n",
       "Name: prediction, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['prediction'] = new_rf_model.predict(df[selected_features], concatened_column_name)\n",
    "df.drop_duplicates(subset=[concatened_column_name])['prediction'].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save model and predicted data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mexporting model and normalization absolutes...\u001b[37m\n"
     ]
    }
   ],
   "source": [
    "new_rf_model.export_model('../data/models/RandomForest_Ksmash_Regex_Enrichments_Normalization.pkl',\n",
    "                          '../data/models/normalization_absolutes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['prediction'] == 1][[concatened_column_name, 'target', 'prediction']] \\\n",
    "    .drop_duplicates(subset=[concatened_column_name]) \\\n",
    "    .to_csv(f'../data/tmp/{time.strftime(\"%Y%m%d-%H%M%S\")}prediction_rf_ks_regex_enrich_normal.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "acd904f7927719ac3bd428a31e6feadbc6c298bbba280a82d6227cca902ecf8e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
