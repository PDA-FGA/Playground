{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anapaula/.local/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2023-01-28 20:08:59.580652: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-28 20:08:59.659490: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-01-28 20:08:59.659504: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-01-28 20:09:00.126530: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-01-28 20:09:00.126588: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-01-28 20:09:00.126592: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import hygia as hg\n",
    "import pickle"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classes instanciations\n",
    "\n",
    "NOTE: Please check if the model_path matches your path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_process_data = hg.PreProcessData()\n",
    "augment_data = hg.AugmentData(country=\"MEXICO\")\n",
    "feature_engineering = hg.FeatureEngineering()\n",
    "annotate_data = hg.AnnotateData()\n",
    "new_rf_model = hg.RandomForestModel()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data\n",
    "\n",
    "NOTE: Please check if the file_path matches your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '../data/tmp/AI_LATA_ADDRESS_MEX_modificado.csv'\n",
    "df = pd.read_csv(file_path, sep='Â¨', nrows=None, engine='python')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add new columns\n",
    "\n",
    "1. Concatenate address\n",
    "2. All features columns:\n",
    "    - Key Smash\n",
    "    - Regex\n",
    "    - Word Embedding\n",
    "\n",
    "NOTE: Please check if the columns names matches your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliases indified: \u001b[1mconcat_STREET_ADDRESS_1_STREET_ADDRESS_2 -> \u001b[22m['STREET_ADDRESS_1', 'STREET_ADDRESS_2']\n",
      "handle null values in the column \u001b[1mconcat_STREET_ADDRESS_1_STREET_ADDRESS_2\u001b[22m\n"
     ]
    }
   ],
   "source": [
    "concatened_column_name = 'concat_STREET_ADDRESS_1_STREET_ADDRESS_2'\n",
    "df = pre_process_data.pre_process_data(df, ['STREET_ADDRESS_1', 'STREET_ADDRESS_2'], concatened_column_name)\n",
    "df = feature_engineering.extract_features(df, concatened_column_name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check new columns names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['feature_ks_count_sequence_squared_vowels_concat_STREET_ADDRESS_1_STREET_ADDRESS_2',\n",
       " 'feature_ks_count_sequence_squared_consonants_concat_STREET_ADDRESS_1_STREET_ADDRESS_2',\n",
       " 'feature_ks_count_sequence_squared_special_characters_concat_STREET_ADDRESS_1_STREET_ADDRESS_2',\n",
       " 'feature_ks_ratio_of_numeric_digits_squared_concat_STREET_ADDRESS_1_STREET_ADDRESS_2',\n",
       " 'feature_ks_average_of_char_count_squared_concat_STREET_ADDRESS_1_STREET_ADDRESS_2',\n",
       " 'feature_we_0_concat_STREET_ADDRESS_1_STREET_ADDRESS_2',\n",
       " 'feature_we_1_concat_STREET_ADDRESS_1_STREET_ADDRESS_2',\n",
       " 'feature_we_2_concat_STREET_ADDRESS_1_STREET_ADDRESS_2',\n",
       " 'feature_we_3_concat_STREET_ADDRESS_1_STREET_ADDRESS_2',\n",
       " 'feature_we_4_concat_STREET_ADDRESS_1_STREET_ADDRESS_2',\n",
       " 'feature_we_5_concat_STREET_ADDRESS_1_STREET_ADDRESS_2',\n",
       " 'feature_we_6_concat_STREET_ADDRESS_1_STREET_ADDRESS_2',\n",
       " 'feature_we_7_concat_STREET_ADDRESS_1_STREET_ADDRESS_2',\n",
       " 'feature_we_8_concat_STREET_ADDRESS_1_STREET_ADDRESS_2',\n",
       " 'feature_we_9_concat_STREET_ADDRESS_1_STREET_ADDRESS_2',\n",
       " 'feature_we_10_concat_STREET_ADDRESS_1_STREET_ADDRESS_2',\n",
       " 'feature_we_11_concat_STREET_ADDRESS_1_STREET_ADDRESS_2',\n",
       " 'feature_we_12_concat_STREET_ADDRESS_1_STREET_ADDRESS_2',\n",
       " 'feature_we_13_concat_STREET_ADDRESS_1_STREET_ADDRESS_2',\n",
       " 'feature_we_14_concat_STREET_ADDRESS_1_STREET_ADDRESS_2',\n",
       " 'feature_we_15_concat_STREET_ADDRESS_1_STREET_ADDRESS_2',\n",
       " 'feature_we_16_concat_STREET_ADDRESS_1_STREET_ADDRESS_2',\n",
       " 'feature_we_17_concat_STREET_ADDRESS_1_STREET_ADDRESS_2',\n",
       " 'feature_we_18_concat_STREET_ADDRESS_1_STREET_ADDRESS_2',\n",
       " 'feature_we_19_concat_STREET_ADDRESS_1_STREET_ADDRESS_2',\n",
       " 'feature_we_20_concat_STREET_ADDRESS_1_STREET_ADDRESS_2',\n",
       " 'feature_we_21_concat_STREET_ADDRESS_1_STREET_ADDRESS_2',\n",
       " 'feature_we_22_concat_STREET_ADDRESS_1_STREET_ADDRESS_2',\n",
       " 'feature_we_23_concat_STREET_ADDRESS_1_STREET_ADDRESS_2',\n",
       " 'feature_we_24_concat_STREET_ADDRESS_1_STREET_ADDRESS_2',\n",
       " 'feature_re_contains_exactly_the_word_dell_concat_STREET_ADDRESS_1_STREET_ADDRESS_2',\n",
       " 'feature_re_contains_exactly_the_word_test_concat_STREET_ADDRESS_1_STREET_ADDRESS_2',\n",
       " 'feature_re_only_numbers_concat_STREET_ADDRESS_1_STREET_ADDRESS_2',\n",
       " 'feature_re_only_special_characters_concat_STREET_ADDRESS_1_STREET_ADDRESS_2',\n",
       " 'feature_re_contains_email_concat_STREET_ADDRESS_1_STREET_ADDRESS_2',\n",
       " 'feature_re_contains_url_concat_STREET_ADDRESS_1_STREET_ADDRESS_2',\n",
       " 'feature_re_contains_date_concat_STREET_ADDRESS_1_STREET_ADDRESS_2',\n",
       " 'feature_re_contains_exactly_invalid_words_concat_STREET_ADDRESS_1_STREET_ADDRESS_2',\n",
       " 'feature_re_is_substring_of_column_name_concat_STREET_ADDRESS_1_STREET_ADDRESS_2',\n",
       " 'feature_re_only_one_char_concat_STREET_ADDRESS_1_STREET_ADDRESS_2',\n",
       " 'feature_re_only_white_spaces_concat_STREET_ADDRESS_1_STREET_ADDRESS_2',\n",
       " 'feature_re_empty_concat_STREET_ADDRESS_1_STREET_ADDRESS_2']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_features_columns = [col for col in df if col.startswith('feature_ks') or col.startswith('feature_we') or col.startswith('feature_re')]\n",
    "all_features_columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Annotate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "valid                             1346998\n",
       "key_smash                             739\n",
       "contains_email                        569\n",
       "contains_exactly_the_word_test        177\n",
       "only_special_characters               144\n",
       "contains_exactly_the_word_dell        125\n",
       "only_numbers                          106\n",
       "only_one_char                          14\n",
       "contains_exactly_invalid_words         10\n",
       "is_substring_of_column_name             3\n",
       "contains_date                           1\n",
       "empty                                   1\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key_smash_thresholds = {\n",
    "    'count_sequence_squared_vowels': 1.00,\n",
    "    'count_sequence_squared_consonants': 1.999,\n",
    "    'count_sequence_squared_special_characters': 2.2499,\n",
    "    'ratio_of_numeric_digits_squared': 2.9,\n",
    "    'average_of_char_count_squared': 2.78,\n",
    "}\n",
    "\n",
    "df = annotate_data.annotate_data(df, concatened_column_name, key_smash_thresholds)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "valid                             2514338\n",
       "key_smash                            1762\n",
       "only_special_characters              1291\n",
       "contains_email                       1048\n",
       "contains_exactly_the_word_test        667\n",
       "contains_exactly_the_word_dell        553\n",
       "only_one_char                         287\n",
       "only_numbers                          239\n",
       "empty                                  71\n",
       "contains_exactly_invalid_words         26\n",
       "is_substring_of_column_name            12\n",
       "contains_date                           2\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['target'].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment: retrain model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.9885931558935361,\n",
       " 'precision': 0.9822222222222222,\n",
       " 'recall': 0.9778761061946902,\n",
       " 'f1': 0.9800443458980044}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = new_rf_model.train_and_get_scores(df, concatened_column_name, all_features_columns)\n",
    "scores"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict using pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anapaula/.local/lib/python3.8/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0    1344545\n",
       "1.0       4342\n",
       "Name: prediction, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['prediction'] = new_rf_model.predict(df[all_features_columns].values)\n",
    "df.drop_duplicates(subset=[concatened_column_name])['prediction'].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save model and predicted data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_rf_model.export_model('../data/models/RandomForest_Ksmash_WordEmbedding_Regex_Enrichments.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['prediction'] == 1][[concatened_column_name, 'prediction']].drop_duplicates(subset=[concatened_column_name]).to_csv('../data/tmp/prediction_enrichments.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['prediction'] = df['target'] == 'key_smash'\n",
    "df['prediction_model'] = df['prediction']\n",
    "df[df['prediction_model']!=df['prediction']][[concatened_column_name, 'target', 'prediction_model', 'prediction']] \\\n",
    "    .drop_duplicates(subset=[concatened_column_name]) \\\n",
    "    .to_csv('../data/tmp/prediction_better_with_model.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10 (default, Mar 15 2022, 12:22:08) \n[GCC 9.4.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
